#Filter the data, removing bigrams where either word is a stop word or the word “applause”
bigrams_separated <- text %>%
separate(bigram,c("word1","word2"),sep = " ")
bigram_filtered <-bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% negations)%>%
filter(!word1 %in% negations)
#new biagram counts:
bigram_filtered %>%
count(word1,word2,sort = TRUE)%>%
top_n(15)%>%
ggplot(aes(x=word1,y=n))+
geom_col(show.legend = FALSE)
bigram_filtered %>%
count(word1,word2,sort = TRUE)%>%
top_n(15)%>%
ggplot(aes(x=word2,y=n))+
geom_col(show.legend = FALSE)
biagram_counts
#removing bigrams where the first word is a negation word such as “never”, “no”, “not”, or “without”. Then plot the top 15 most common bigrams in Trump’s speeches.
#negation words
negations <- c("never", "no", "not","without")
#Filter the data, removing bigrams where either word is a stop word or the word “applause”
bigrams_separated <- text %>%
separate(bigram,c("word1","word2"),sep = " ")
bigram_filtered <-bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% negations)%>%
filter(!word1 %in% negations)
#new biagram counts:
bigram_filtered %>%
count(word1,word2,sort = TRUE)%>%
top_n(15)%>%
ggplot(aes(x=word1,y=n))+
geom_col(show.legend = FALSE)
bigram_filtered %>%
count(word1,word2,sort = TRUE)%>%
top_n(15)%>%
ggplot(aes(x=word2,y=n))+
geom_col(show.legend = FALSE)
#removing bigrams where the first word is a negation word such as “never”, “no”, “not”, or “without”. Then plot the top 15 most common bigrams in Trump’s speeches.
#negation words
negations <- c("never", "no", "not","without")
#Filter the data, removing bigrams where either word is a stop word or the word “applause”
bigrams_separated <- text %>%
separate(bigram,c("word1","word2"),sep = " ")
bigram_filtered <-bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% negations)%>%
filter(!word1 %in% negations)%>%
count(word1,word2,sort = TRUE)
#Then plot the top 15 most common bigrams in Trump’s speeches.
bigram_filtered %>%
count(word1,word2,sort = TRUE)%>%
top_n(15)%>%
ggplot(aes(x=word1,y=n))+
geom_col(show.legend = FALSE)
#negation words
negations <- c("never", "no", "not","without")
#Filter the data, removing bigrams where either word is a stop word or the word “applause”
bigrams_separated <- text %>%
separate(bigram,c("word1","word2"),sep = " ")
bigram_filtered <-bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% negations)%>%
filter(!word1 %in% negations)
#Then plot the top 15 most common bigrams in Trump’s speeches.
bigram_filtered %>%
count(word1,word2,sort = TRUE)%>%
top_n(15)%>%
ggplot(aes(x=word1,y=n))+
geom_col(show.legend = FALSE)
bigram_filtered %>%
count(word1,word2,sort = TRUE)%>%
top_n(15)%>%
ggplot(aes(x=word2,y=n))+
geom_col(show.legend = FALSE)
#negation words
negations <- c("never", "no", "not","without")
#Filter the data, removing bigrams where either word is a stop word or the word “applause”
bigrams_separated <- text %>%
separate(bigram,c("word1","word2"),sep = " ")
bigram_filtered <-bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% negations)%>%
filter(!word1 %in% negations)
bigram_filtered%>%
count(word1,word2,sort = TRUE)
#Then plot the top 15 most common bigrams in Trump’s speeches.
bigram_filtered %>%
count(word1,word2,sort = TRUE)%>%
top_n(15)%>%
ggplot(aes(x=word1,y=n))+
geom_col(show.legend = FALSE)
bigram_filtered %>%
count(word1,word2,sort = TRUE)%>%
top_n(15)%>%
ggplot(aes(x=word2,y=n))+
geom_col(show.legend = FALSE)
#negation words
negations <- c("never", "no", "not","without")
#Filter the data, removing bigrams where either word is a stop word or the word “applause”
bigrams_separated <- text %>%
separate(bigram,c("word1","word2"),sep = " ")
bigram_filtered <-bigrams_separated %>%
filter(!word1 %in% c(stop_words$word,"applause") %>%
filter(!word2 %in% c(stop_words$word,"applause") %>%
filter(!word2 %in% negations)%>%
filter(!word1 %in% negations)
bigram_filtered%>%
#negation words
negations <- c("never", "no", "not","without","applause")
#Filter the data, removing bigrams where either word is a stop word or the word “applause”
bigrams_separated <- text %>%
separate(bigram,c("word1","word2"),sep = " ")
bigram_filtered <-bigrams_separated %>%
filter(!word1 %in% c(stop_words$word) %>%
filter(!word2 %in% negations)%>%
filter(!word1 %in% negations)
bigram_filtered%>%
#negation words
negations <- c("never", "no", "not","without","applause")
#Filter the data, removing bigrams where either word is a stop word or the word “applause”
bigrams_separated <- text %>%
separate(bigram,c("word1","word2"),sep = " ")
bigram_filtered <-bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% negations)%>%
filter(!word1 %in% negations)
bigram_filtered%>%
count(word1,word2,sort = TRUE)
#Then plot the top 15 most common bigrams in Trump’s speeches.
bigram_filtered %>%
count(word1,word2,sort = TRUE)%>%
top_n(15)%>%
ggplot(aes(x=word1,y=n))+
geom_col(show.legend = FALSE)
bigram_filtered %>%
count(word1,word2,sort = TRUE)%>%
top_n(15)%>%
ggplot(aes(x=word2,y=n))+
geom_col(show.legend = FALSE)
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
bigram_filtered <-bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)
#(top ~5) words preceded (separately) by each of “never”, “no”, “not”, and “without”.
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
bigram_filtered <-bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)
bigram_filtered
#(top ~5) words preceded (separately) by each of “never”, “no”, “not”, and “without”.
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
bigram_filtered <-bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
top_n(5)%>%
ggplot(aes(x=word2,y=n))+
geom_col(show.legend = FALSE)+
facet_wrap(~word1,scales = "free")+
coord_flip()
#(top ~5) words preceded (separately) by each of “never”, “no”, “not”, and “without”.
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
top_n(5)%>%
ggplot(aes(x=word2,y=n))+
geom_col(show.legend = FALSE)+
facet_wrap(~word1,scales = "free")+
coord_flip()
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
top_n(5)%>%
ggplot(aes(x=word1,y=n))+
geom_col(show.legend = FALSE)+
facet_wrap(~word1,scales = "free")+
coord_flip()
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
group_by(word2)
top_n(5)%>%
ggplot(aes(word1,n))+
geom_col(show.legend = FALSE)+
facet_wrap(~word1,scales = "free")+
coord_flip()
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
group_by(word1)%>%
top_n(5)%>%
ggplot(aes(word1,n))+
geom_col(show.legend = FALSE)+
facet_wrap(~word1,scales = "free")+
coord_flip()
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
speech_neg<-bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
count(word1,word2,sort = True)%>%
ungroup()
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
speech_neg<-bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
count(word1,word2,sort = TRUE)%>%
ungroup()
top_n(5)%>%
ggplot(aes(word1,n))+
geom_col(show.legend = FALSE)+
facet_wrap(~word1,scales = "free")+
coord_flip()
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
speech_neg<-bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
count(word1,word2,sort = TRUE)%>%
ungroup()
speech_neg %>%
arrange(desc(n))%>%
mutate(word2=reorder(words1,n))%>%
group_by(word2)
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
speech_neg<-bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
count(word1,word2,sort = TRUE)%>%
ungroup()
speech_neg %>%
arrange(desc(n))%>%
mutate(word2=reorder(word1,n))%>%
group_by(word2)
top_n(5)%>%
ggplot(aes(word1,n))+
geom_col(show.legend = FALSE)+
facet_wrap(~word1,scales = "free")+
coord_flip()
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
speech_neg<-bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
count(word1,word2,sort = TRUE)%>%
ungroup()
speech_neg %>%
arrange(desc(n))%>%
mutate(word2=reorder(word2,n))%>%
group_by(word1)
top_n(5)%>%
ggplot(aes(word2,n))+
geom_col(show.legend = FALSE)+
facet_wrap(~word1,scales = "free")+
coord_flip()
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
speech_neg<-bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
count(word1,word2,sort = TRUE)%>%
ungroup()
speech_neg %>%
arrange(desc(n))%>%
mutate(word2=reorder(word2,n))%>%
group_by(word1)
top_n(5)
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
speech_neg<-bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
count(word1,word2,sort = TRUE)%>%
ungroup()
speech_neg %>%
arrange(desc(n))%>%
mutate(word2=reorder(word2,n))%>%
group_by(word1)%>%
top_n(5)
#(top ~5) words preceded (separately) by each of “never”, “no”, “not”, and “without”.
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
speech_neg<-bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
count(word1,word2,sort = TRUE)%>%
ungroup()
speech_neg %>%
arrange(desc(n))%>%
mutate(word2=reorder(word2,n))%>%
group_by(word1)%>%
top_n(5)%>%
ggplot(aes(word2,n))+
geom_col(show.legend = FALSE)+
facet_wrap(~word1,scales = 'free')+
coord_flip()
#(top ~5) words preceded (separately) by each of “never”, “no”, “not”, and “without”.
#We would like to see the most commonly negated words in Donald Trump’s speeches, and how they’re negated. Filter the bigrams, keeping only bigrams where the first word is any of “not”, “no”, “never”, or “without”, and removing those where the second word is a stop word or “applause”. Then visualize the most common
applause <- c("applause")
speech_neg<-bigrams_separated %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word2 %in% applause)%>%
filter(word1 %in% negations)%>%
count(word1,word2,sort = TRUE)%>%
ungroup()
speech_neg %>%
arrange(desc(n))%>%
mutate(word2=reorder(word2,n))%>%
group_by(word1)%>%
top_n(5)%>%
ggplot(aes(word2,n))+
geom_col(show.legend = FALSE)+
xlab("negated words")+
ylab("sentiment contribution")+
facet_wrap(~word1,scales = 'free')+
coord_flip()
#(top ~5) words preceded (separately) by each of “never”, “no”, “not”, and “without”.
shiny::runApp('Documents/Shiny')
install.packages(c("d3heatmap", "DT", "fuzzyjoin", "ggraph", "highcharter", "igraph", "lexicon", "plotly", "rdrop2", "rsconnect", "shinycssloaders", "shinythemes", "shinyWidgets", "treemap", "visNetwork"))
install.packages(c("d3heatmap", "DT", "fuzzyjoin", "ggraph", "highcharter", "igraph", "lexicon", "plotly", "rdrop2", "rsconnect", "shinycssloaders", "shinythemes", "shinyWidgets", "treemap", "visNetwork"))
runApp('Documents/Shiny')
library(dbplyr)
runApp('Documents/Shiny')
install.packages("dplyr")
runApp('Documents/Shiny')
runApp('Documents/Shiny')
runApp('Documents/Shiny')
runApp('Documents/Shiny')
runApp('Documents/Shiny')
install.packages(c("assertthat", "backports", "BH", "bit", "blob", "boot", "broom", "callr", "class", "cli", "clipr", "cluster", "codetools", "colorspace", "corrr", "covr", "curl", "data.table", "DBI", "dbplyr", "dendextend", "devtools", "digest", "dslabs", "dsr", "dtplyr", "evaluate", "feather", "flexmix", "forcats", "foreach", "forecast", "foreign", "fpc", "fracdiff", "gclus", "ggplot2", "ggrepel", "ggvis", "git2r", "glue", "gplots", "gtable", "haven", "highr", "hms", "httr", "hunspell", "imputeTS", "ISOcodes", "iterators", "kernlab", "KernSmooth", "knitr", "Lahman", "lattice", "lazyeval", "leaps", "lmtest", "mapproj", "markdown", "MASS", "Matrix", "mclust", "measurements", "mgcv", "microbenchmark", "mime", "modelr", "modeltools", "mvtnorm", "nlme", "nnet", "nycflights13", "openssl", "pkgconfig", "plyr", "prabclus", "prettyunits", "processx", "ps", "quadprog", "quantmod", "R6", "RcppArmadillo", "readr", "readxl", "registry", "reprex", "rmarkdown", "RMySQL", "robustbase", "rpart", "RSQLite", "rstudioapi", "rvest", "scales", "selectr", "seriation", "SnowballC", "stopwords", "stringi", "stringr", "survival", "testthat", "tidyr", "tidytext", "tidyverse", "tinytex", "trimcluster", "tseries", "TSP", "TTR", "uroot", "whisker", "xfun", "xml2", "xtable", "xts", "yaml", "zoo"))
install.packages(c("assertthat", "backports", "BH", "bit", "blob", "boot", "broom", "callr", "class", "cli", "clipr", "cluster", "codetools", "colorspace", "corrr", "covr", "curl", "data.table", "DBI", "dbplyr", "dendextend", "devtools", "digest", "dslabs", "dsr", "dtplyr", "evaluate", "feather", "flexmix", "forcats", "foreach", "forecast", "foreign", "fpc", "fracdiff", "gclus", "ggplot2", "ggrepel", "ggvis", "git2r", "glue", "gplots", "gtable", "haven", "highr", "hms", "httr", "hunspell", "imputeTS", "ISOcodes", "iterators", "kernlab", "KernSmooth", "knitr", "Lahman", "lattice", "lazyeval", "leaps", "lmtest", "mapproj", "markdown", "MASS", "Matrix", "mclust", "measurements", "mgcv", "microbenchmark", "mime", "modelr", "modeltools", "mvtnorm", "nlme", "nnet", "nycflights13", "openssl", "pkgconfig", "plyr", "prabclus", "prettyunits", "processx", "ps", "quadprog", "quantmod", "R6", "RcppArmadillo", "readr", "readxl", "registry", "reprex", "rmarkdown", "RMySQL", "robustbase", "rpart", "RSQLite", "rstudioapi", "rvest", "scales", "selectr", "seriation", "SnowballC", "stopwords", "stringi", "stringr", "survival", "testthat", "tidyr", "tidytext", "tidyverse", "tinytex", "trimcluster", "tseries", "TSP", "TTR", "uroot", "whisker", "xfun", "xml2", "xtable", "xts", "yaml", "zoo"))
install.packages(c("assertthat", "backports", "BH", "bit", "blob", "boot", "broom", "callr", "class", "cli", "clipr", "cluster", "codetools", "colorspace", "corrr", "covr", "curl", "data.table", "DBI", "dbplyr", "dendextend", "devtools", "digest", "dslabs", "dsr", "dtplyr", "evaluate", "feather", "flexmix", "forcats", "foreach", "forecast", "foreign", "fpc", "fracdiff", "gclus", "ggplot2", "ggrepel", "ggvis", "git2r", "glue", "gplots", "gtable", "haven", "highr", "hms", "httr", "hunspell", "imputeTS", "ISOcodes", "iterators", "kernlab", "KernSmooth", "knitr", "Lahman", "lattice", "lazyeval", "leaps", "lmtest", "mapproj", "markdown", "MASS", "Matrix", "mclust", "measurements", "mgcv", "microbenchmark", "mime", "modelr", "modeltools", "mvtnorm", "nlme", "nnet", "nycflights13", "openssl", "pkgconfig", "plyr", "prabclus", "prettyunits", "processx", "ps", "quadprog", "quantmod", "R6", "RcppArmadillo", "readr", "readxl", "registry", "reprex", "rmarkdown", "RMySQL", "robustbase", "rpart", "RSQLite", "rstudioapi", "rvest", "scales", "selectr", "seriation", "SnowballC", "stopwords", "stringi", "stringr", "survival", "testthat", "tidyr", "tidytext", "tidyverse", "tinytex", "trimcluster", "tseries", "TSP", "TTR", "uroot", "whisker", "xfun", "xml2", "xtable", "xts", "yaml", "zoo"))
install.packages(c("assertthat", "backports", "BH", "bit", "blob", "boot", "broom", "callr", "class", "cli", "clipr", "cluster", "codetools", "colorspace", "corrr", "covr", "curl", "data.table", "DBI", "dbplyr", "dendextend", "devtools", "digest", "dslabs", "dsr", "dtplyr", "evaluate", "feather", "flexmix", "forcats", "foreach", "forecast", "foreign", "fpc", "fracdiff", "gclus", "ggplot2", "ggrepel", "ggvis", "git2r", "glue", "gplots", "gtable", "haven", "highr", "hms", "httr", "hunspell", "imputeTS", "ISOcodes", "iterators", "kernlab", "KernSmooth", "knitr", "Lahman", "lattice", "lazyeval", "leaps", "lmtest", "mapproj", "markdown", "MASS", "Matrix", "mclust", "measurements", "mgcv", "microbenchmark", "mime", "modelr", "modeltools", "mvtnorm", "nlme", "nnet", "nycflights13", "openssl", "pkgconfig", "plyr", "prabclus", "prettyunits", "processx", "ps", "quadprog", "quantmod", "R6", "RcppArmadillo", "readr", "readxl", "registry", "reprex", "rmarkdown", "RMySQL", "robustbase", "rpart", "RSQLite", "rstudioapi", "rvest", "scales", "selectr", "seriation", "SnowballC", "stopwords", "stringi", "stringr", "survival", "testthat", "tidyr", "tidytext", "tidyverse", "tinytex", "trimcluster", "tseries", "TSP", "TTR", "uroot", "whisker", "xfun", "xml2", "xtable", "xts", "yaml", "zoo"))
install.packages(c("assertthat", "backports", "BH", "bit", "blob", "boot", "broom", "callr", "class", "cli", "clipr", "cluster", "codetools", "colorspace", "corrr", "covr", "curl", "data.table", "DBI", "dbplyr", "dendextend", "devtools", "digest", "dslabs", "dsr", "dtplyr", "evaluate", "feather", "flexmix", "forcats", "foreach", "forecast", "foreign", "fpc", "fracdiff", "gclus", "ggplot2", "ggrepel", "ggvis", "git2r", "glue", "gplots", "gtable", "haven", "highr", "hms", "httr", "hunspell", "imputeTS", "ISOcodes", "iterators", "kernlab", "KernSmooth", "knitr", "Lahman", "lattice", "lazyeval", "leaps", "lmtest", "mapproj", "markdown", "MASS", "Matrix", "mclust", "measurements", "mgcv", "microbenchmark", "mime", "modelr", "modeltools", "mvtnorm", "nlme", "nnet", "nycflights13", "openssl", "pkgconfig", "plyr", "prabclus", "prettyunits", "processx", "ps", "quadprog", "quantmod", "R6", "RcppArmadillo", "readr", "readxl", "registry", "reprex", "rmarkdown", "RMySQL", "robustbase", "rpart", "RSQLite", "rstudioapi", "rvest", "scales", "selectr", "seriation", "SnowballC", "stopwords", "stringi", "stringr", "survival", "testthat", "tidyr", "tidytext", "tidyverse", "tinytex", "trimcluster", "tseries", "TSP", "TTR", "uroot", "whisker", "xfun", "xml2", "xtable", "xts", "yaml", "zoo"))
install.packages(c("assertthat", "backports", "BH", "bit", "blob", "boot", "broom", "callr", "class", "cli", "clipr", "cluster", "codetools", "colorspace", "corrr", "covr", "curl", "data.table", "DBI", "dbplyr", "dendextend", "devtools", "digest", "dslabs", "dsr", "dtplyr", "evaluate", "feather", "flexmix", "forcats", "foreach", "forecast", "foreign", "fpc", "fracdiff", "gclus", "ggplot2", "ggrepel", "ggvis", "git2r", "glue", "gplots", "gtable", "haven", "highr", "hms", "httr", "hunspell", "imputeTS", "ISOcodes", "iterators", "kernlab", "KernSmooth", "knitr", "Lahman", "lattice", "lazyeval", "leaps", "lmtest", "mapproj", "markdown", "MASS", "Matrix", "mclust", "measurements", "mgcv", "microbenchmark", "mime", "modelr", "modeltools", "mvtnorm", "nlme", "nnet", "nycflights13", "openssl", "pkgconfig", "plyr", "prabclus", "prettyunits", "processx", "ps", "quadprog", "quantmod", "R6", "RcppArmadillo", "readr", "readxl", "registry", "reprex", "rmarkdown", "RMySQL", "robustbase", "rpart", "RSQLite", "rstudioapi", "rvest", "scales", "selectr", "seriation", "SnowballC", "stopwords", "stringi", "stringr", "survival", "testthat", "tidyr", "tidytext", "tidyverse", "tinytex", "trimcluster", "tseries", "TSP", "TTR", "uroot", "whisker", "xfun", "xml2", "xtable", "xts", "yaml", "zoo"))
shiny::runApp('~/Documents/Shiny')
runApp('Documents/Shiny')
runApp('Documents/Shiny')
runApp('Documents/Shiny')
n<- dataInput_heat%>%
group_by_(col1,col2)
shiny::runApp('Documents/Shiny')
shiny::runApp('Desktop/CrisprDepmapShinyAPP ')
shiny::runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
knitr::opts_chunk$set(echo = TRUE)
data(MisLinks)
library(shiny)
library(networkD3)
data(MisLinks)
MisLinks
data(MisLinks)
data(MisNodes)
MisNodes
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
m
m$source
runApp('Desktop/app')
m
runApp('Desktop/app')
m
m
m
m
runApp('Desktop/app')
m
runApp('Desktop/app')
m
n
n
Q
runApp('Desktop/app')
m
m
runApp('Desktop/app')
m
m
runApp('Desktop/app')
runApp('Desktop/app')
m
install.packages("igraph")
runApp('Desktop/app')
m
runApp('Desktop/app')
m
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
install.packages("magrittr")
runApp('Desktop/app')
runApp()
runApp('Desktop/app')
runApp()
runApp('Desktop/app')
runApp()
runApp()
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
runApp('Desktop/app')
shiny::runApp('Desktop/Animalcrossing/compatibility')
runApp('Desktop/Animalcrossing/compatibility')
runApp('Desktop/Animalcrossing/compatibility')
runApp('Desktop/Animalcrossing/compatibility')
runApp('Desktop/Animalcrossing/compatibility')
runApp('Desktop/Animalcrossing/compatibility')
runApp('Documents/GitHub/CrisprShinyAPP')
runApp('Desktop/Animalcrossing/compatibility')
runApp('Desktop/Animalcrossing/compatibility')
runApp('Desktop/Animalcrossing/compatibility')
runApp('Desktop/Animalcrossing/compatibility')
shiny::runApp('Documents/GitHub/CrisprShinyAPP')
shiny::runApp('Documents/GitHub/CrisprShinyAPP')
runApp()
runApp('Documents/GitHub/CrisprShinyAPP')
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
df <- read.csv("corr_rank_within70.txt", header = TRUE,stringsAsFactors = FALSE)
nrow(df)
for (i in 1:nrow(df)){df[i, ] = sort(df[i, ])}
for (i in 1:nrow(df)){
print(i/2631717)
df[i, ] = sort(df[i, ])
}
for (i in 1:nrow(df)){
n=(i/2631717 * 100)
if(n%%10==0){
print(n)
}
df[i, ] = sort(df[i, ])
}
for (i in 1:nrow(df)){
n=(i/2631717 * 100)
print(n)
df[i, ] = sort(df[i, ])
}
shiny::runApp()
df <- read.csv("corr_rank_within70.txt", header = TRUE,stringsAsFactors = FALSE)
nrow(df)
df
knitr::opts_chunk$set(echo = TRUE)
df
cols = c(Gene,Gene2)
newdf = df[,'Gene']
newdf
newdf = df[,c('Gene','Gene2')]
newdf
cols = c('Gene','Gene2')
newdf = df[,cols]
newdf
cols
for (i in 1:nrow(df)){
n=(i/2631717 * 100)
print(n)
df[i, ] = sort(df[i,cols ])
}
shiny::runApp()
